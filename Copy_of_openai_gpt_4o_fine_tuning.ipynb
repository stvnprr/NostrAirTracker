{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stvnprr/NostrAirTracker/blob/master/Copy_of_openai_gpt_4o_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# OpenAI GPT-4o fine-tuning\n",
        "---"
      ],
      "metadata": {
        "id": "qxRhs8smCtFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "qgabw2nPowqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure your API keys\n",
        "\n",
        "To fine-tune GPT-4o, you need to provide your OpenAI API key and Roboflow API key. Follow these steps:\n",
        "\n",
        "- Open your [`OpenAI Settings`](https://platform.openai.com/settings) page. Click `User API keys` then `Create new secret key` to generate new token.\n",
        "- Go to your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (🔑).\n",
        "    - Store OpenAI API key under the name `OPENAI_API_KEY`.\n",
        "    - Store Roboflow API Key under the name `ROBOFLOW_API_KEY`."
      ],
      "metadata": {
        "id": "_U2G3NfcozRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "yGb7ydD1pwC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xC6GaDomrrN",
        "outputId": "4f5ed983-5b08-42c4-88f1-e776172bd5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.3/151.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai roboflow supervision maestro==0.2.0rc5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "QBZNvweDq_O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "workspace = rf.workspace(\"roboflow-jvuqo\")\n",
        "project = workspace.project(\"poker-cards-fmjio\")\n",
        "version = project.version(4)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF3PKCH6p9Ca",
        "outputId": "cfe555d1-e11b-4d8c-dff5-042c5328780e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in poker-cards-4 to yolov8:: 100%|██████████| 39352/39352 [00:01<00:00, 38072.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to poker-cards-4 in yolov8:: 100%|██████████| 1810/1810 [00:00<00:00, 5504.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "ds_train = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f'{dataset.location}/train/images',\n",
        "    annotations_directory_path=f'{dataset.location}/train/labels',\n",
        "    data_yaml_path=f'{dataset.location}/data.yaml'\n",
        ")\n",
        "ds_valid = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f'{dataset.location}/valid/images',\n",
        "    annotations_directory_path=f'{dataset.location}/valid/labels',\n",
        "    data_yaml_path=f'{dataset.location}/data.yaml'\n",
        ")\n",
        "ds_test = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f'{dataset.location}/test/images',\n",
        "    annotations_directory_path=f'{dataset.location}/test/labels',\n",
        "    data_yaml_path=f'{dataset.location}/data.yaml'\n",
        ")\n",
        "\n",
        "print(ds_train.classes)\n",
        "print(len(ds_train), len(ds_valid), len(ds_test))"
      ],
      "metadata": {
        "id": "-CD4xdEcJ0yN",
        "outputId": "cc3fce8e-2588-476f-b923-4f2edf1d7b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10 of clubs', '10 of diamonds', '10 of hearts', '10 of spades', '2 of clubs', '2 of diamonds', '2 of hearts', '2 of spades', '3 of clubs', '3 of diamonds', '3 of hearts', '3 of spades', '4 of clubs', '4 of diamonds', '4 of hearts', '4 of spades', '5 of clubs', '5 of diamonds', '5 of hearts', '5 of spades', '6 of clubs', '6 of diamonds', '6 of hearts', '6 of spades', '7 of clubs', '7 of diamonds', '7 of hearts', '7 of spades', '8 of clubs', '8 of diamonds', '8 of hearts', '8 of spades', '9 of clubs', '9 of diamonds', '9 of hearts', '9 of spades', 'ace of clubs', 'ace of diamonds', 'ace of hearts', 'ace of spades', 'jack  of clubs', 'jack of diamonds', 'jack of hearts', 'jack of spades', 'king of clubs', 'king of diamonds', 'king of hearts', 'king of spades', 'queen of clubs', 'queen of diamonds', 'queen of hearts', 'queen of spades']\n",
            "811 44 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL_PREFIX = \"https://storage.googleapis.com/com-roboflow-marketing/gpt-4o-fine-tuning/poker-cards/\"\n",
        "\n",
        "\n",
        "def use_template(prefix: str, suffix: str, image: str) -> dict:\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prefix},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": image\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": suffix\n",
        "            }\n",
        "        ]\n",
        "    }"
      ],
      "metadata": {
        "id": "zI9r1I_ZNloX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def process_prefix(prefix: str, class_ids: np.ndarray, classes: list[str], separator: str = ';') -> str:\n",
        "    \"\"\"\n",
        "    Constructs a string where a prefix appears once at the beginning followed by\n",
        "    class names corresponding to the class IDs, separated by the specified separator.\n",
        "\n",
        "    Args:\n",
        "        prefix (str): The string to prepend before the class names.\n",
        "        class_ids (np.ndarray): Array of integers representing the class IDs.\n",
        "        classes (list[str]): List of class names corresponding to the IDs.\n",
        "        separator (str, optional): Separator used between class names. Defaults to ';'.\n",
        "\n",
        "    Returns:\n",
        "        str: A single string starting with the prefix followed by class names.\n",
        "    \"\"\"\n",
        "    selected_classes = [classes[i] for i in class_ids]\n",
        "    return f\"{prefix} \" + separator.join(selected_classes)"
      ],
      "metadata": {
        "id": "4LUAF0WEeYJ5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def process_suffix(detections, image: np.ndarray, classes: list[str], separator: str = ';') -> str:\n",
        "    \"\"\"\n",
        "    Constructs a string where class names are followed by their normalized bounding box\n",
        "    locations, separated by the specified separator.\n",
        "\n",
        "    Args:\n",
        "        detections: Object containing detection results with 'xyxy' (bounding boxes),\n",
        "            'class_id' (class IDs), and 'image_shape' (height, width, channels).\n",
        "        classes (list[str]): List of class names corresponding to the class IDs.\n",
        "        separator (str, optional): Separator used between class entries. Defaults to ';'.\n",
        "\n",
        "    Returns:\n",
        "        str: A string of class names with their corresponding bounding box locations.\n",
        "    \"\"\"\n",
        "    xyxy = detections.xyxy\n",
        "    class_id = detections.class_id\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    x_centers = (xyxy[:, 0] + xyxy[:, 2]) / 2\n",
        "    y_centers = (xyxy[:, 1] + xyxy[:, 3]) / 2\n",
        "    idx = np.lexsort((y_centers, x_centers))\n",
        "\n",
        "    sorted_xyxy = xyxy[idx] / np.array([w, h, w, h]) * 1024\n",
        "    sorted_xyxy = sorted_xyxy.astype(int)\n",
        "    sorted_class_id = class_id[idx]\n",
        "\n",
        "    entries = [\n",
        "        f\"<loc{y_min:04d}><loc{x_min:04d}><loc{y_max:04d}><loc{x_max:04d}> {classes[id]}\"\n",
        "        for id, (x_min, y_min, x_max, y_max) in zip(sorted_class_id, sorted_xyxy)\n",
        "    ]\n",
        "\n",
        "    return separator.join(entries)"
      ],
      "metadata": {
        "id": "QqaoCc7GP1GQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def process_path(path: str, prefix: str) -> str:\n",
        "    \"\"\"\n",
        "    Takes a file path and a URL prefix, and replaces the local part of the path up to\n",
        "    the folder of interest (like 'train/images') with the prefix.\n",
        "\n",
        "    Args:\n",
        "        path (str): The local file path.\n",
        "        prefix (str): The URL prefix to prepend to the remaining path.\n",
        "\n",
        "    Returns:\n",
        "        str: The final URL with the prefix and cleaned-up path.\n",
        "    \"\"\"\n",
        "    # Extract the part of the path starting from 'train/images' or another folder of interest\n",
        "    cleaned_path = os.path.join(*path.split('/')[-3:])  # Keeps only the last 3 parts\n",
        "\n",
        "    # Concatenate the prefix with the cleaned-up path\n",
        "    return prefix + cleaned_path"
      ],
      "metadata": {
        "id": "Iegrmwa-R0_m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import e\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "def save_entries_as_jsonl(entries: list, path: Path) -> None:\n",
        "    with open(path, 'w') as f:\n",
        "        for i, entry in enumerate(tqdm(entries, desc=f\"saving entries to {path}\")):\n",
        "            json.dump(entry, f)\n",
        "            if i < len(entries) - 1:\n",
        "                f.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "def dataset_as_jsonl(dataset, annotations_file: str, max_count: int = None) -> None:\n",
        "    \"\"\"\n",
        "    Saves the dataset in JSONL format by processing the images, detections, and paths.\n",
        "\n",
        "    Args:\n",
        "        dataset: The dataset containing image paths, image data, and detection results.\n",
        "        annotations_file (str): The path where the JSONL file will be saved.\n",
        "        max_count (int, optional): Maximum number of dataset entries to process. If None, processes the entire dataset.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    entries = []\n",
        "    total_entries = len(dataset) if max_count is None else min(len(dataset), max_count)\n",
        "\n",
        "    for i in tqdm(range(total_entries), desc=f\"saving images at {annotations_file}\"):\n",
        "        path, image, detections = dataset[i]\n",
        "        prefix = process_prefix(\n",
        "            prefix='detect',\n",
        "            class_ids=detections.class_id,\n",
        "            classes=dataset.classes\n",
        "        )\n",
        "        suffix = process_suffix(\n",
        "            detections=detections,\n",
        "            image=image,\n",
        "            classes=dataset.classes\n",
        "        )\n",
        "        image = process_path(path=path, prefix=URL_PREFIX)\n",
        "        entry = use_template(prefix=prefix, suffix=suffix, image=image)\n",
        "        entries.append(entry)\n",
        "\n",
        "    save_entries_as_jsonl(entries=entries, path=annotations_file)"
      ],
      "metadata": {
        "id": "O6mSjicpVpC7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_as_jsonl(ds_train, \"_annotations.train.jsonl\")\n",
        "dataset_as_jsonl(ds_valid, \"_annotations.valid.jsonl\")\n",
        "dataset_as_jsonl(ds_test, \"_annotations.test.jsonl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmnphhFJXqZx",
        "outputId": "653f422f-46b0-4c8f-bba3-1d85e438cb2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "saving images at _annotations.train.jsonl: 100%|██████████| 811/811 [00:01<00:00, 433.48it/s]\n",
            "saving entries to _annotations.train.jsonl: 100%|██████████| 811/811 [00:00<00:00, 23931.54it/s]\n",
            "saving images at _annotations.valid.jsonl: 100%|██████████| 44/44 [00:00<00:00, 429.30it/s]\n",
            "saving entries to _annotations.valid.jsonl: 100%|██████████| 44/44 [00:00<00:00, 9866.84it/s]\n",
            "saving images at _annotations.test.jsonl: 100%|██████████| 44/44 [00:00<00:00, 387.08it/s]\n",
            "saving entries to _annotations.test.jsonl: 100%|██████████| 44/44 [00:00<00:00, 10654.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 1 _annotations.train.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B19KY1Outib6",
        "outputId": "7d84432d-c991-483d-ac9f-1c57a47cce68"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"detect 5 of diamonds;6 of diamonds;7 of diamonds;8 of diamonds\"}, {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": \"https://storage.googleapis.com/com-roboflow-marketing/gpt-4o-fine-tuning/poker-cards/train/images/IMG_20220316_163940_jpg.rf.feb9ea9ba3e0795b2f794ed03e009f6a.jpg\"}}]}, {\"role\": \"assistant\", \"content\": \"<loc0240><loc0052><loc0848><loc0433> 5 of diamonds;<loc0263><loc0408><loc0772><loc0642> 6 of diamonds;<loc0316><loc0640><loc0740><loc0813> 7 of diamonds;<loc0340><loc0808><loc0732><loc0916> 8 of diamonds\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run GPT-4o fine-tuning\n",
        "\n",
        "**NOTE:** At the time of publishing this notebook, only the `gpt-4o-2024-08-06` model can be fine-tuned with vision datasets."
      ],
      "metadata": {
        "id": "SFcFQvocuqn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initiate OpenAI client\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "uc4fjWVQxP_b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload a training and validation file\n",
        "\n",
        "training_file_upload_response = client.files.create(\n",
        "  file=open(\"_annotations.train.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "validation_file_upload_response = client.files.create(\n",
        "  file=open(\"_annotations.valid.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(\"treaining file response:\", training_file_upload_response)\n",
        "print(\"validation file response:\", validation_file_upload_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grniVs2Xw8i8",
        "outputId": "118d87e5-40ee-4608-921f-16c8e093c839"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treaining file response: FileObject(id='file-70RxNt3rxh6kaJUrXPjv3moI', bytes=548591, created_at=1727982014, filename='_annotations.train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
            "validation file response: FileObject(id='file-giYhb4bQnqIoavF8rP3nRC66', bytes=30010, created_at=1727982014, filename='_annotations.valid.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create a fine-tuned model\n",
        "\n",
        "import re\n",
        "\n",
        "def process_suffix(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts a string into kebab-case, where spaces are replaced with hyphens\n",
        "    and all letters are lowercase.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string to be converted. Typically, words are\n",
        "          separated by spaces.\n",
        "\n",
        "    Returns:\n",
        "        str: The kebab-case version of the input string, where spaces are\n",
        "          replaced by hyphens and the text is lowercase.\n",
        "\n",
        "    Example:\n",
        "        >>> process_suffix(\"Focal Length\")\n",
        "        'focal-length'\n",
        "    \"\"\"\n",
        "    return re.sub(r'\\s+', '-', text.strip()).lower()\n",
        "\n",
        "\n",
        "fine_tuning_response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_upload_response.id,\n",
        "    validation_file=validation_file_upload_response.id,\n",
        "    suffix=process_suffix(dataset.name),\n",
        "    model=\"gpt-4o-2024-08-06\"\n",
        ")\n",
        "\n",
        "fine_tuning_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95eRs4VmrNJL",
        "outputId": "1927918b-d04f-40a4-913d-615094adbb7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-CCTalNeoiSuZ1oKMKKvPDGqX', created_at=1727982025, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-CXJ1IDVkLDojjsLoQszn4eiV', result_files=[], seed=1350904141, status='validating_files', trained_tokens=None, training_file='file-70RxNt3rxh6kaJUrXPjv3moI', validation_file='file-giYhb4bQnqIoavF8rP3nRC66', estimated_finish=None, integrations=[], user_provided_suffix='poker-cards')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ After you've started a fine-tuning job, it may take some time to complete. Your job may be queued behind other jobs in our system, and training a model can take minutes or hours depending on the model and dataset size. After the model training is completed, the user who created the fine-tuning job will receive an email confirmation.\n",
        "\n",
        "In addition to creating a fine-tuning job, you can also list existing jobs, retrieve the status of a job, or cancel a job."
      ],
      "metadata": {
        "id": "a1GmSlqtzlT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check training job status\n",
        "\n",
        "status_response = client.fine_tuning.jobs.retrieve(fine_tuning_response.id)\n",
        "\n",
        "status_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rGTqH0-vwAM",
        "outputId": "e64be315-c9a4-41ed-cae9-df0e41f0d33f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-CCTalNeoiSuZ1oKMKKvPDGqX', created_at=1727982025, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-CXJ1IDVkLDojjsLoQszn4eiV', result_files=[], seed=1350904141, status='running', trained_tokens=None, training_file='file-70RxNt3rxh6kaJUrXPjv3moI', validation_file='file-giYhb4bQnqIoavF8rP3nRC66', estimated_finish=None, integrations=[], user_provided_suffix='poker-cards')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** When the training status changes to `succeeded`, the model is ready to use."
      ],
      "metadata": {
        "id": "zCqb-Gkx_RIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load test dataset\n",
        "\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from maestro.trainer.common.utils.file_system import read_jsonl\n",
        "\n",
        "class JSONLDataset(Dataset):\n",
        "    \"\"\"A dataset class for loading and managing JSONL data in a PyTorch-compatible format.\n",
        "\n",
        "    This class allows loading JSONL files, shuffling the data, and accessing\n",
        "    individual data points using standard PyTorch Dataset interfaces.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_jsonl_file(cls, path: str):\n",
        "        \"\"\"Loads data from a JSONL file, shuffles it, and returns a dataset instance.\n",
        "\n",
        "        Args:\n",
        "            path (str): The file path to the JSONL file.\n",
        "\n",
        "        Returns:\n",
        "            JSONLDataset: An instance of the JSONLDataset class loaded with the JSON data.\n",
        "        \"\"\"\n",
        "        file_content = read_jsonl(path=path)\n",
        "        random.shuffle(file_content)\n",
        "        return cls(jsons=file_content)\n",
        "\n",
        "    def __init__(self, jsons: list[dict]) -> None:\n",
        "        \"\"\"Initializes the dataset with a list of JSON objects.\n",
        "\n",
        "        Args:\n",
        "            jsons (list[dict]): A list of JSON objects, each represented as a dictionary.\n",
        "        \"\"\"\n",
        "        self.jsons = jsons\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Fetches a specific item from the dataset.\n",
        "\n",
        "        Args:\n",
        "            index (int): The index of the item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary representing the JSON object at the specified index.\n",
        "        \"\"\"\n",
        "        return self.jsons[index]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Returns the number of items in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The total number of JSON objects in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.jsons)\n",
        "\n",
        "    def shuffle(self) -> None:\n",
        "        \"\"\"Shuffles the JSON objects in the dataset.\n",
        "\n",
        "        This method modifies the dataset in place, changing the order of the JSON objects.\n",
        "        \"\"\"\n",
        "        random.shuffle(self.jsons)\n",
        "\n",
        "\n",
        "def extract_image_url(data):\n",
        "    \"\"\"Extracts the first image URL from a list of messages in a dataset.\n",
        "\n",
        "    The function searches through messages to find an image URL\n",
        "    where the 'role' is 'user' and 'content' is a list containing items\n",
        "    with a 'type' of 'image_url'.\n",
        "\n",
        "    Args:\n",
        "        data (list[dict]): A list of message dictionaries.\n",
        "\n",
        "    Returns:\n",
        "        str or None: The image URL if found, otherwise None.\n",
        "    \"\"\"\n",
        "    for message in data:\n",
        "        if message['role'] == 'user' and isinstance(message['content'], list):\n",
        "            for item in message['content']:\n",
        "                if item.get('type') == 'image_url':\n",
        "                    return item['image_url']['url']\n",
        "    return None\n",
        "\n",
        "\n",
        "test_dataset = JSONLDataset.from_jsonl_file(\"_annotations.test.jsonl\")"
      ],
      "metadata": {
        "id": "WhmepSHgymL6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** When querying the model, we need to remove the last element of the messages list, which contains the expected model response."
      ],
      "metadata": {
        "id": "HAJLtZ2i-3xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]['messages']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRI5rqLH_o7u",
        "outputId": "9a017314-0f2f-404e-c0aa-297e118e21ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
              " {'role': 'user',\n",
              "  'content': 'detect 5 of hearts;6 of hearts;7 of hearts;8 of hearts'},\n",
              " {'role': 'user',\n",
              "  'content': [{'type': 'image_url',\n",
              "    'image_url': {'url': 'https://storage.googleapis.com/com-roboflow-marketing/gpt-4o-fine-tuning/poker-cards/test/images/IMG_20220316_144507_jpg.rf.ab9b95792bbdbe7694910967641fba38.jpg'}}]},\n",
              " {'role': 'assistant',\n",
              "  'content': '<loc0347><loc0000><loc0908><loc0351> 5 of hearts;<loc0333><loc0334><loc0791><loc0576> 6 of hearts;<loc0327><loc0586><loc0752><loc0829> 7 of hearts;<loc0328><loc0803><loc0700><loc1024> 8 of hearts'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run inference using fine-tuned model\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=status_response.fine_tuned_model,\n",
        "    messages=test_dataset[0]['messages'][:-1]\n",
        ")\n",
        "\n",
        "completion.choices[0].message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "W8YspUe648Sz",
        "outputId": "392b1064-9f07-464e-9e98-8a38abaa68dc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': 'you must provide a model parameter', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-95d54e673406>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Run inference using fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tuned_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    740\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    741\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         )\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'you must provide a model parameter', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
          ]
        }
      ]
    },
    {
      "source": [
        "# @title Run inference using fine-tuned model\n",
        "\n",
        "# Ensure status_response is defined and contains the fine-tuned model ID\n",
        "if status_response and status_response.fine_tuned_model:\n",
        "    completion = client.chat.completions.create(\n",
        "        model=status_response.fine_tuned_model,\n",
        "        messages=test_dataset[0]['messages'][:-1]\n",
        "    )\n",
        "\n",
        "    print(completion.choices[0].message)\n",
        "else:\n",
        "    print(\"Error: status_response or fine_tuned_model is not defined or empty. Please check your fine-tuning process.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tZz78QGqxSSH",
        "outputId": "d8372151-a0ad-4878-87bc-ac85d31f93f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: status_response or fine_tuned_model is not defined or empty. Please check your fine-tuning process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Post-process inference result\n",
        "\n",
        "import requests\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "\n",
        "URL = extract_image_url(test_dataset[0]['messages'])\n",
        "\n",
        "image = Image.open(requests.get(URL, stream=True).raw)\n",
        "detections = sv.Detections.from_lmm(\n",
        "    lmm=sv.LMM.PALIGEMMA,\n",
        "    result=completion.choices[0].message.content,\n",
        "    resolution_wh=image.size\n",
        ")\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "label_annotator = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(\n",
        "    scene=image,\n",
        "    detections=detections\n",
        ")\n",
        "annotated_image = label_annotator.annotate(\n",
        "    scene=annotated_image,\n",
        "    detections=detections\n",
        ")\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "eUNY6x_hrcNq",
        "outputId": "4ac631e3-5bff-4a71-c43b-963c38de4017"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'completion' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1d4bf2199f2d>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m detections = sv.Detections.from_lmm(\n\u001b[1;32m     11\u001b[0m     \u001b[0mlmm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLMM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPALIGEMMA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mresolution_wh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'completion' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run inference on multiple images\n",
        "\n",
        "SAMPLE = 16\n",
        "\n",
        "annotated_images = []\n",
        "\n",
        "for i in tqdm(range(SAMPLE)):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=status_response.fine_tuned_model,\n",
        "        messages=test_dataset[i]['messages'][:-1]\n",
        "    )\n",
        "\n",
        "    url = extract_image_url(test_dataset[i]['messages'])\n",
        "\n",
        "    image = Image.open(requests.get(url, stream=True).raw)\n",
        "    detections = sv.Detections.from_lmm(\n",
        "        lmm=sv.LMM.PALIGEMMA,\n",
        "        result=completion.choices[0].message.content,\n",
        "        resolution_wh=image.size\n",
        "    )\n",
        "\n",
        "    box_annotator = sv.BoxAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "    label_annotator = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "\n",
        "    annotated_image = image.copy()\n",
        "    annotated_image = box_annotator.annotate(\n",
        "        scene=image,\n",
        "        detections=detections\n",
        "    )\n",
        "    annotated_image = label_annotator.annotate(\n",
        "        scene=annotated_image,\n",
        "        detections=detections\n",
        "    )\n",
        "    annotated_images.append(annotated_image)\n",
        "\n",
        "sv.plot_images_grid(annotated_images, grid_size=(4, 4), size=(16, 16))"
      ],
      "metadata": {
        "id": "uLfSmlQEkgoa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}